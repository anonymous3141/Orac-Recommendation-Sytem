Testing model with K = 2 and lambda = 0.01
Beginning to train
Iteration #1: Loss = 0.9591237549293131
Iteration #2: Loss = 0.9466301692908778
Iteration #3: Loss = 0.933335656276799
Iteration #4: Loss = 0.9189925966245238
Iteration #5: Loss = 0.9035681196867129
Iteration #6: Loss = 0.8870692033351503
Iteration #7: Loss = 0.8695631990137217
Iteration #8: Loss = 0.8512549872332621
Iteration #9: Loss = 0.8325033085047148
Iteration #10: Loss = 0.8137865248789494
Iteration #11: Loss = 0.7956395461287255
Iteration #12: Loss = 0.7785710948617695
Iteration #13: Loss = 0.7629910362163622
Iteration #14: Loss = 0.749168627879471
Iteration #15: Loss = 0.7372242633302081
Iteration #16: Loss = 0.7271461904038284
Iteration #17: Loss = 0.7188212780021722
Iteration #18: Loss = 0.7120695996637503
Iteration #19: Loss = 0.7066766611607818
Iteration #20: Loss = 0.7024206846038855
Iteration #21: Loss = 0.699092853943657
Iteration #22: Loss = 0.6965093388931938
Iteration #23: Loss = 0.6945194149384882
Iteration #24: Loss = 0.693004447746884
Iteration #25: Loss = 0.6918676466213488
Iteration #26: Loss = 0.6910260427644139
Iteration #27: Loss = 0.6904082421384491
Iteration #28: Loss = 0.6899546421300736
Iteration #29: Loss = 0.6896155826136442
Iteration #30: Loss = 0.6893535377474632
Iteration #31: Loss = 0.6891445446467226
Iteration #32: Loss = 0.6889716676784825
Iteration #33: Loss = 0.688824313873656
Iteration #34: Loss = 0.688697786505384
Iteration #35: Loss = 0.6885893244217604
Iteration #36: Loss = 0.6884955896664792
Iteration #37: Loss = 0.688412019587602
Iteration #38: Loss = 0.688333850532979
Iteration #39: Loss = 0.6882578131202508
Iteration #40: Loss = 0.6881829866554977
Iteration #41: Loss = 0.6881104412431478
Iteration #42: Loss = 0.6880421677203944
Iteration #43: Loss = 0.6879800253518379
Iteration #44: Loss = 0.6879249574014524
Iteration #45: Loss = 0.6878763826470665
Iteration #46: Loss = 0.6878323597623478
Iteration #47: Loss = 0.6877906357162554
Iteration #48: Loss = 0.6877493633481293
Iteration #49: Loss = 0.6877071470207602
Iteration #50: Loss = 0.687663314642521
Iteration #51: Loss = 0.6876178134193613
Iteration #52: Loss = 0.6875709909343256
Iteration #53: Loss = 0.6875232396358826
Iteration #54: Loss = 0.6874748720026167
Iteration #55: Loss = 0.6874264046537328
Iteration #56: Loss = 0.6873785078197354
Iteration #57: Loss = 0.6873316854017644
Iteration #58: Loss = 0.6872861610212773
Iteration #59: Loss = 0.6872419483425026
Iteration #60: Loss = 0.6871987968664133
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4383408071748879
Top 20 Accuracy: 0.48094170403587444
Top N+5 Accuracy: 0.4585201793721973
Testing model with K = 2 and lambda = 0.05
Beginning to train
Iteration #1: Loss = 0.9588953056847571
Iteration #2: Loss = 0.9467757984605831
Iteration #3: Loss = 0.934601819891073
Iteration #4: Loss = 0.9220105270426169
Iteration #5: Loss = 0.9088476148171468
Iteration #6: Loss = 0.894930911117651
Iteration #7: Loss = 0.8800441070218563
Iteration #8: Loss = 0.8640459752954924
Iteration #9: Loss = 0.8469698412135215
Iteration #10: Loss = 0.8290776214505444
Iteration #11: Loss = 0.8108356767749649
Iteration #12: Loss = 0.7928362820052497
Iteration #13: Loss = 0.7756982802433727
Iteration #14: Loss = 0.7599682312739882
Iteration #15: Loss = 0.7460412336042351
Iteration #16: Loss = 0.7341184617347154
Iteration #17: Loss = 0.7242093952733137
Iteration #18: Loss = 0.716172055410942
Iteration #19: Loss = 0.7097735647029216
Iteration #20: Loss = 0.7047497999881777
Iteration #21: Loss = 0.7008481475665219
Iteration #22: Loss = 0.6978478617890571
Iteration #23: Loss = 0.6955624642915192
Iteration #24: Loss = 0.6938372155733733
Iteration #25: Loss = 0.6925445619388368
Iteration #26: Loss = 0.691578877780128
Iteration #27: Loss = 0.6908555685732692
Iteration #28: Loss = 0.6903107347340594
Iteration #29: Loss = 0.6898987156037631
Iteration #30: Loss = 0.6895878203960516
Iteration #31: Loss = 0.6893548891803433
Iteration #32: Loss = 0.689179297071826
Iteration #33: Loss = 0.6890381429553251
Iteration #34: Loss = 0.6889101176591913
Iteration #35: Loss = 0.6887860737548547
Iteration #36: Loss = 0.6886691626952391
Iteration #37: Loss = 0.6885663857046485
Iteration #38: Loss = 0.6884817968803666
Iteration #39: Loss = 0.6884146165069841
Iteration #40: Loss = 0.6883613456719401
Iteration #41: Loss = 0.6883173233342248
Iteration #42: Loss = 0.6882773558267733
Iteration #43: Loss = 0.6882375132247704
Iteration #44: Loss = 0.6881962934417176
Iteration #45: Loss = 0.6881538591826809
Iteration #46: Loss = 0.688110770961472
Iteration #47: Loss = 0.6880674582877992
Iteration #48: Loss = 0.6880244605725253
Iteration #49: Loss = 0.6879826563097786
Iteration #50: Loss = 0.6879429540085732
Iteration #51: Loss = 0.6879058304957246
Iteration #52: Loss = 0.6878712848702486
Iteration #53: Loss = 0.6878391534465471
Iteration #54: Loss = 0.6878092319902271
Iteration #55: Loss = 0.6877809772814566
Iteration #56: Loss = 0.6877536567934386
Iteration #57: Loss = 0.6877270321433825
Iteration #58: Loss = 0.6877013651203292
Iteration #59: Loss = 0.6876769387429759
Iteration #60: Loss = 0.6876537062490644
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4405829596412556
Top 20 Accuracy: 0.49551569506726456
Top N+5 Accuracy: 0.4663677130044843
Testing model with K = 2 and lambda = 0.1
Beginning to train
Iteration #1: Loss = 0.957146291475208
Iteration #2: Loss = 0.9444869631559477
Iteration #3: Loss = 0.9314566418534065
Iteration #4: Loss = 0.9171264646223191
Iteration #5: Loss = 0.9012085447784698
Iteration #6: Loss = 0.8836857989906827
Iteration #7: Loss = 0.8647899198109594
Iteration #8: Loss = 0.8449643299992947
Iteration #9: Loss = 0.8247905865410514
Iteration #10: Loss = 0.8049107342136359
Iteration #11: Loss = 0.7859489326679101
Iteration #12: Loss = 0.7684413360838687
Iteration #13: Loss = 0.7527849841714227
Iteration #14: Loss = 0.7392134192484111
Iteration #15: Loss = 0.7277994397470187
Iteration #16: Loss = 0.7184773140351111
Iteration #17: Loss = 0.711074539097461
Iteration #18: Loss = 0.7053484855949216
Iteration #19: Loss = 0.7010236462029642
Iteration #20: Loss = 0.6978231358234981
Iteration #21: Loss = 0.6954920703794173
Iteration #22: Loss = 0.6938110846748845
Iteration #23: Loss = 0.6926008788782625
Iteration #24: Loss = 0.6917230155591719
Iteration #25: Loss = 0.6910779146153587
Iteration #26: Loss = 0.6905966679777903
Iteration #27: Loss = 0.6902312998939074
Iteration #28: Loss = 0.6899489001297667
Iteration #29: Loss = 0.6897285700064931
Iteration #30: Loss = 0.6895559500060551
Iteration #31: Loss = 0.6894163758583706
Iteration #32: Loss = 0.6892956486064774
Iteration #33: Loss = 0.6891833808351473
Iteration #34: Loss = 0.6890737560380341
Iteration #35: Loss = 0.6889659029157157
Iteration #36: Loss = 0.6888628129899445
Iteration #37: Loss = 0.6887690364496112
Iteration #38: Loss = 0.6886879161109536
Iteration #39: Loss = 0.6886198914311609
Iteration #40: Loss = 0.6885632015250679
Iteration #41: Loss = 0.6885157216949248
Iteration #42: Loss = 0.6884756896734007
Iteration #43: Loss = 0.6884416041376552
Iteration #44: Loss = 0.6884122658575456
Iteration #45: Loss = 0.6883867983918045
Iteration #46: Loss = 0.6883642735811907
Iteration #47: Loss = 0.6883436209073001
Iteration #48: Loss = 0.6883242666704287
Iteration #49: Loss = 0.68830617005303
Iteration #50: Loss = 0.6882896051289848
Iteration #51: Loss = 0.6882750771388731
Iteration #52: Loss = 0.6882632466637902
Iteration #53: Loss = 0.6882547706474441
Iteration #54: Loss = 0.6882501123693234
Iteration #55: Loss = 0.6882494347741693
used 54 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.42937219730941706
Top 20 Accuracy: 0.47757847533632286
Top N+5 Accuracy: 0.45739910313901344
Testing model with K = 2 and lambda = 0.5
Beginning to train
Iteration #1: Loss = 0.9581510835804166
Iteration #2: Loss = 0.9449068728020779
Iteration #3: Loss = 0.9312001200704451
Iteration #4: Loss = 0.9165421632493319
Iteration #5: Loss = 0.9006832250298443
Iteration #6: Loss = 0.8835546003461591
Iteration #7: Loss = 0.8653199530251787
Iteration #8: Loss = 0.846350554600518
Iteration #9: Loss = 0.8271505572707287
Iteration #10: Loss = 0.8082794816205998
Iteration #11: Loss = 0.790284388217107
Iteration #12: Loss = 0.7736420982783397
Iteration #13: Loss = 0.7587144576012689
Iteration #14: Loss = 0.7457211691652333
Iteration #15: Loss = 0.7347338000882413
Iteration #16: Loss = 0.7256908440659205
Iteration #17: Loss = 0.7184287578239461
Iteration #18: Loss = 0.7127206185063402
Iteration #19: Loss = 0.7083138302828477
Iteration #20: Loss = 0.7049604661136267
Iteration #21: Loss = 0.7024375369632712
Iteration #22: Loss = 0.7005573253501346
Iteration #23: Loss = 0.6991694880791665
Iteration #24: Loss = 0.6981573309803146
Iteration #25: Loss = 0.6974318489256195
Iteration #26: Loss = 0.6969272624483904
Iteration #27: Loss = 0.6965969201412618
Iteration #28: Loss = 0.6964080403120299
Iteration #29: Loss = 0.6963371507406338
Iteration #30: Loss = 0.6963668012485086
Iteration #31: Loss = 0.6964829911759773
Iteration #32: Loss = 0.6966732028861087
Iteration #33: Loss = 0.6969252137453229
Iteration #34: Loss = 0.6972265705826705
Iteration #35: Loss = 0.6975644055815818
Iteration #36: Loss = 0.6979254313984861
Iteration #37: Loss = 0.6982961309312818
Iteration #38: Loss = 0.6986631514573859
Iteration #39: Loss = 0.6990138412401399
Iteration #40: Loss = 0.6993368289083939
Iteration #41: Loss = 0.6996225498063261
Iteration #42: Loss = 0.6998636452625681
Iteration #43: Loss = 0.7000551848610986
Iteration #44: Loss = 0.7001946929366668
Iteration #45: Loss = 0.7002820004716134
Iteration #46: Loss = 0.700318976558676
Iteration #47: Loss = 0.7003091965994778
Iteration #48: Loss = 0.7002575782487682
Iteration #49: Loss = 0.7001699938905181
Iteration #50: Loss = 0.7000528714686237
Iteration #51: Loss = 0.6999128082608361
Iteration #52: Loss = 0.6997562256467589
Iteration #53: Loss = 0.6995890903328997
Iteration #54: Loss = 0.6994167235850064
Iteration #55: Loss = 0.6992437057520818
Iteration #56: Loss = 0.6990738590520058
Iteration #57: Loss = 0.6989102759753293
Iteration #58: Loss = 0.6987553639301518
Iteration #59: Loss = 0.6986108903745312
Iteration #60: Loss = 0.698478027047911
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4103139013452915
Top 20 Accuracy: 0.47533632286995514
Top N+5 Accuracy: 0.4439461883408072
Testing model with K = 2 and lambda = 1
Beginning to train
Iteration #1: Loss = 0.9574964515819633
Iteration #2: Loss = 0.9434086584547074
Iteration #3: Loss = 0.9295282371092435
Iteration #4: Loss = 0.9155470687996236
Iteration #5: Loss = 0.9008965203546963
Iteration #6: Loss = 0.8854528146558422
Iteration #7: Loss = 0.8694983016996193
Iteration #8: Loss = 0.8534512867425675
Iteration #9: Loss = 0.837727587960015
Iteration #10: Loss = 0.8226853858524751
Iteration #11: Loss = 0.8086053505830891
Iteration #12: Loss = 0.7956858683541963
Iteration #13: Loss = 0.7840459811509342
Iteration #14: Loss = 0.7737333130333411
Iteration #15: Loss = 0.7647354900133049
Iteration #16: Loss = 0.7569936038583256
Iteration #17: Loss = 0.7504162196243037
Iteration #18: Loss = 0.7448925712286204
Iteration #19: Loss = 0.740303936955849
Iteration #20: Loss = 0.7365325241310939
Iteration #21: Loss = 0.7334674251004248
Iteration #22: Loss = 0.731007774432167
Iteration #23: Loss = 0.7290638642473833
Iteration #24: Loss = 0.7275570203671202
Iteration #25: Loss = 0.7264188184135353
Iteration #26: Loss = 0.7255899777312144
Iteration #27: Loss = 0.7250190752079821
Iteration #28: Loss = 0.72466121618926
Iteration #29: Loss = 0.7244768647799769
Iteration #30: Loss = 0.7244309836763921
Iteration #31: Loss = 0.7244924962283317
Iteration #32: Loss = 0.724633948708676
Iteration #33: Loss = 0.7248312358445591
Iteration #34: Loss = 0.7250633634978216
Iteration #35: Loss = 0.7253122887843696
Iteration #36: Loss = 0.7255628398253631
Iteration #37: Loss = 0.725802656253985
Iteration #38: Loss = 0.7260220858846407
Iteration #39: Loss = 0.7262140215083027
Iteration #40: Loss = 0.7263736996540382
Iteration #41: Loss = 0.7264984761701483
Iteration #42: Loss = 0.7265875694409847
Iteration #43: Loss = 0.7266417626325876
Iteration #44: Loss = 0.7266630826460634
Iteration #45: Loss = 0.7266544881582672
Iteration #46: Loss = 0.7266195851997811
Iteration #47: Loss = 0.7265623699760532
Iteration #48: Loss = 0.7264869985116938
Iteration #49: Loss = 0.7263975919695593
Iteration #50: Loss = 0.726298084959021
Iteration #51: Loss = 0.7261921133305604
Iteration #52: Loss = 0.7260829332377817
Iteration #53: Loss = 0.7259733676901401
Iteration #54: Loss = 0.7258657802955379
Iteration #55: Loss = 0.725762073394364
Iteration #56: Loss = 0.7256637044665296
Iteration #57: Loss = 0.7255717152971024
Iteration #58: Loss = 0.7254867709153601
Iteration #59: Loss = 0.7254092058030968
Iteration #60: Loss = 0.7253390736294064
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4147982062780269
Top 20 Accuracy: 0.476457399103139
Top N+5 Accuracy: 0.4484304932735426
Testing model with K = 3 and lambda = 0.01
Beginning to train
Iteration #1: Loss = 0.9581311347863707
Iteration #2: Loss = 0.946212652735253
Iteration #3: Loss = 0.9337223323151786
Iteration #4: Loss = 0.9200888564070073
Iteration #5: Loss = 0.9050257575867476
Iteration #6: Loss = 0.8883716318702244
Iteration #7: Loss = 0.8701486341363291
Iteration #8: Loss = 0.8505920055417994
Iteration #9: Loss = 0.8301434111479539
Iteration #10: Loss = 0.809426153743247
Iteration #11: Loss = 0.7891934833355697
Iteration #12: Loss = 0.770224590861084
Iteration #13: Loss = 0.753186604895758
Iteration #14: Loss = 0.7385182649795738
Iteration #15: Loss = 0.7263803863318963
Iteration #16: Loss = 0.7166838802019322
Iteration #17: Loss = 0.7091706155341448
Iteration #18: Loss = 0.7035025938648138
Iteration #19: Loss = 0.6993278554848597
Iteration #20: Loss = 0.6963199656137101
Iteration #21: Loss = 0.6941979183978888
Iteration #22: Loss = 0.6927281708771494
Iteration #23: Loss = 0.6917204021165575
Iteration #24: Loss = 0.6910272186415667
Iteration #25: Loss = 0.6905438758839485
Iteration #26: Loss = 0.6902020051863795
Iteration #27: Loss = 0.6899554265521483
Iteration #28: Loss = 0.689762278080134
Iteration #29: Loss = 0.6895886362953983
Iteration #30: Loss = 0.6894258647322457
Iteration #31: Loss = 0.6892774973899304
Iteration #32: Loss = 0.6891448315461178
Iteration #33: Loss = 0.6890273700882464
Iteration #34: Loss = 0.6889237523779876
Iteration #35: Loss = 0.6888273942012997
Iteration #36: Loss = 0.6887322344907373
Iteration #37: Loss = 0.6886386491949485
Iteration #38: Loss = 0.688548717441173
Iteration #39: Loss = 0.6884629172023895
Iteration #40: Loss = 0.6883842361834814
Iteration #41: Loss = 0.6883184632583496
Iteration #42: Loss = 0.6882680682031559
Iteration #43: Loss = 0.6882254718013285
Iteration #44: Loss = 0.6881776649332544
Iteration #45: Loss = 0.688119075383926
Iteration #46: Loss = 0.6880538177230049
Iteration #47: Loss = 0.687989991973375
Iteration #48: Loss = 0.6879334185208967
Iteration #49: Loss = 0.687885794785547
Iteration #50: Loss = 0.6878463901567362
Iteration #51: Loss = 0.6878122719469808
Iteration #52: Loss = 0.6877792981756721
Iteration #53: Loss = 0.6877439731136197
Iteration #54: Loss = 0.6877045355093889
Iteration #55: Loss = 0.6876610808961022
Iteration #56: Loss = 0.6876154660340601
Iteration #57: Loss = 0.6875699139147294
Iteration #58: Loss = 0.6875253580354457
Iteration #59: Loss = 0.6874821656226958
Iteration #60: Loss = 0.6874410093734571
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4484304932735426
Top 20 Accuracy: 0.5022421524663677
Top N+5 Accuracy: 0.4742152466367713
Testing model with K = 3 and lambda = 0.05
Beginning to train
Iteration #1: Loss = 0.9592561406178095
Iteration #2: Loss = 0.9468129701016046
Iteration #3: Loss = 0.9332950998290849
Iteration #4: Loss = 0.9179248615709399
Iteration #5: Loss = 0.9003896072207628
Iteration #6: Loss = 0.880689801711498
Iteration #7: Loss = 0.8592060955815889
Iteration #8: Loss = 0.8366461155307052
Iteration #9: Loss = 0.8139273769533384
Iteration #10: Loss = 0.7920314178662581
Iteration #11: Loss = 0.7718449041872837
Iteration #12: Loss = 0.7540228793792947
Iteration #13: Loss = 0.7389176725455391
Iteration #14: Loss = 0.726588289895753
Iteration #15: Loss = 0.7168626287672489
Iteration #16: Loss = 0.7094168072337474
Iteration #17: Loss = 0.7038564476481552
Iteration #18: Loss = 0.6997865871321077
Iteration #19: Loss = 0.6968550177169873
Iteration #20: Loss = 0.6947680281731934
Iteration #21: Loss = 0.6932897493904646
Iteration #22: Loss = 0.6922374802391322
Iteration #23: Loss = 0.6914788227633124
Iteration #24: Loss = 0.6909237520128432
Iteration #25: Loss = 0.6905081705238912
Iteration #26: Loss = 0.6901868851473594
Iteration #27: Loss = 0.6899310130209669
Iteration #28: Loss = 0.6897248663166621
Iteration #29: Loss = 0.689563746936435
Iteration #30: Loss = 0.6894438836716363
Iteration #31: Loss = 0.6893441131222283
Iteration #32: Loss = 0.689238236218509
Iteration #33: Loss = 0.6891201443522871
Iteration #34: Loss = 0.6889995602979536
Iteration #35: Loss = 0.6888883247519639
Iteration #36: Loss = 0.6887921671839601
Iteration #37: Loss = 0.6887080763330268
Iteration #38: Loss = 0.6886297437368492
Iteration #39: Loss = 0.6885541405817031
Iteration #40: Loss = 0.6884793115895824
Iteration #41: Loss = 0.6884008446643051
Iteration #42: Loss = 0.6883177307613368
Iteration #43: Loss = 0.6882350533175057
Iteration #44: Loss = 0.6881565247860115
Iteration #45: Loss = 0.6880819240751209
Iteration #46: Loss = 0.6880109237429188
Iteration #47: Loss = 0.6879440598746727
Iteration #48: Loss = 0.6878813402011259
Iteration #49: Loss = 0.687822428449334
Iteration #50: Loss = 0.6877672249931005
Iteration #51: Loss = 0.6877155761182201
Iteration #52: Loss = 0.6876661543614457
Iteration #53: Loss = 0.687616889902658
Iteration #54: Loss = 0.687565994070117
Iteration #55: Loss = 0.6875124034213981
Iteration #56: Loss = 0.6874555793901346
Iteration #57: Loss = 0.687395804509183
Iteration #58: Loss = 0.6873349876904942
Iteration #59: Loss = 0.6872756409299092
Iteration #60: Loss = 0.6872180492563278
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.44506726457399104
Top 20 Accuracy: 0.5033632286995515
Top N+5 Accuracy: 0.47085201793721976
Testing model with K = 3 and lambda = 0.1
Beginning to train
Iteration #1: Loss = 0.960036823915398
Iteration #2: Loss = 0.9475530199080701
Iteration #3: Loss = 0.9339570462510962
Iteration #4: Loss = 0.9184187321793499
Iteration #5: Loss = 0.9005193339763427
Iteration #6: Loss = 0.8802971436662071
Iteration #7: Loss = 0.8582131091394045
Iteration #8: Loss = 0.8350438538736039
Iteration #9: Loss = 0.8117626479670589
Iteration #10: Loss = 0.7893934100916947
Iteration #11: Loss = 0.7688536802577511
Iteration #12: Loss = 0.7508225020864789
Iteration #13: Loss = 0.73566749947453
Iteration #14: Loss = 0.7234427805258645
Iteration #15: Loss = 0.7139464324834698
Iteration #16: Loss = 0.7068119333769458
Iteration #17: Loss = 0.7016021910631228
Iteration #18: Loss = 0.6978846995148156
Iteration #19: Loss = 0.6952804272257551
Iteration #20: Loss = 0.6934843074650715
Iteration #21: Loss = 0.6922626686100121
Iteration #22: Loss = 0.6914375935633705
Iteration #23: Loss = 0.6908752940942956
Iteration #24: Loss = 0.6904828218620295
Iteration #25: Loss = 0.6902010054783648
Iteration #26: Loss = 0.6899941011760495
Iteration #27: Loss = 0.689838220058263
Iteration #28: Loss = 0.6897130659733754
Iteration #29: Loss = 0.6896006046158832
Iteration #30: Loss = 0.6894900550353692
Iteration #31: Loss = 0.6893808107275267
Iteration #32: Loss = 0.6892787179903607
Iteration #33: Loss = 0.689187307052759
Iteration #34: Loss = 0.6890990170606034
Iteration #35: Loss = 0.6890018676646692
Iteration #36: Loss = 0.6888918317163135
Iteration #37: Loss = 0.6887724367365067
Iteration #38: Loss = 0.6886520861497784
Iteration #39: Loss = 0.6885419404645472
Iteration #40: Loss = 0.6884524449293927
Iteration #41: Loss = 0.6883890104725237
Iteration #42: Loss = 0.6883488369364681
Iteration #43: Loss = 0.6883225918408438
Iteration #44: Loss = 0.6882999742134419
Iteration #45: Loss = 0.6882734476717729
Iteration #46: Loss = 0.6882389971568388
Iteration #47: Loss = 0.6881958416880705
Iteration #48: Loss = 0.6881459476924595
Iteration #49: Loss = 0.688092863014605
Iteration #50: Loss = 0.6880401273818713
Iteration #51: Loss = 0.6879905613940537
Iteration #52: Loss = 0.6879463583061036
Iteration #53: Loss = 0.6879089560388545
Iteration #54: Loss = 0.6878780917242235
Iteration #55: Loss = 0.6878521025668305
Iteration #56: Loss = 0.6878293593651702
Iteration #57: Loss = 0.6878088474669395
Iteration #58: Loss = 0.6877900663567492
Iteration #59: Loss = 0.6877729629260754
Iteration #60: Loss = 0.6877578090100006
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4316143497757848
Top 20 Accuracy: 0.48654708520179374
Top N+5 Accuracy: 0.45739910313901344
Testing model with K = 3 and lambda = 0.5
Beginning to train
Iteration #1: Loss = 0.9575091636030014
Iteration #2: Loss = 0.943406868568276
Iteration #3: Loss = 0.9277244505614691
Iteration #4: Loss = 0.9099182210902131
Iteration #5: Loss = 0.8900891176482106
Iteration #6: Loss = 0.8684725652165661
Iteration #7: Loss = 0.8455832195102067
Iteration #8: Loss = 0.8222337496147577
Iteration #9: Loss = 0.7994030502156626
Iteration #10: Loss = 0.7780658057262702
Iteration #11: Loss = 0.7590345015446717
Iteration #12: Loss = 0.7428396057569209
Iteration #13: Loss = 0.729674259614286
Iteration #14: Loss = 0.7194168230139412
Iteration #15: Loss = 0.7117170521547119
Iteration #16: Loss = 0.706109974794886
Iteration #17: Loss = 0.702118162027077
Iteration #18: Loss = 0.6993186995840712
Iteration #19: Loss = 0.697372877514707
Iteration #20: Loss = 0.6960283269730875
Iteration #21: Loss = 0.6951045109026242
Iteration #22: Loss = 0.6944740903228407
Iteration #23: Loss = 0.694052167926191
Iteration #24: Loss = 0.6937866645696584
Iteration #25: Loss = 0.6936449786190828
Iteration #26: Loss = 0.6936038536070784
Iteration #27: Loss = 0.693646672732855
Iteration #28: Loss = 0.6937637667052463
Iteration #29: Loss = 0.6939498140971059
Iteration #30: Loss = 0.6941998379119981
Iteration #31: Loss = 0.694506622693517
Iteration #32: Loss = 0.694860307192074
Iteration #33: Loss = 0.6952488747214903
Iteration #34: Loss = 0.6956581787850223
Iteration #35: Loss = 0.6960720917580967
Iteration #36: Loss = 0.6964734500799795
Iteration #37: Loss = 0.6968455253053562
Iteration #38: Loss = 0.6971735263315669
Iteration #39: Loss = 0.6974458391340087
Iteration #40: Loss = 0.6976547461229835
Iteration #41: Loss = 0.697796553444818
Iteration #42: Loss = 0.697871314220745
Iteration #43: Loss = 0.6978823419527364
Iteration #44: Loss = 0.6978355952191493
Iteration #45: Loss = 0.6977389875911988
Iteration #46: Loss = 0.6976016772526575
Iteration #47: Loss = 0.6974333536161146
Iteration #48: Loss = 0.6972435498009139
Iteration #49: Loss = 0.6970410611528277
Iteration #50: Loss = 0.6968335489370998
Iteration #51: Loss = 0.6966273558131129
Iteration #52: Loss = 0.696427508776912
Iteration #53: Loss = 0.6962378447629499
Iteration #54: Loss = 0.6960611692480733
Iteration #55: Loss = 0.6958993827086107
Iteration #56: Loss = 0.6957535699914772
Iteration #57: Loss = 0.6956240850663116
Iteration #58: Loss = 0.6955106574305345
Iteration #59: Loss = 0.6954125225986851
Iteration #60: Loss = 0.695328561742972
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4327354260089686
Top 20 Accuracy: 0.5044843049327354
Top N+5 Accuracy: 0.4697309417040359
Testing model with K = 3 and lambda = 1
Beginning to train
Iteration #1: Loss = 0.9596213708240259
Iteration #2: Loss = 0.944646660053196
Iteration #3: Loss = 0.9286984124667376
Iteration #4: Loss = 0.9112947138423584
Iteration #5: Loss = 0.8923073658654153
Iteration #6: Loss = 0.8721134746853481
Iteration #7: Loss = 0.8514430520097661
Iteration #8: Loss = 0.8310966321239641
Iteration #9: Loss = 0.8117867534022507
Iteration #10: Loss = 0.7940649223948547
Iteration #11: Loss = 0.778294130628518
Iteration #12: Loss = 0.764650228675397
Iteration #13: Loss = 0.7531445613285277
Iteration #14: Loss = 0.7436608897672787
Iteration #15: Loss = 0.7359986482532149
Iteration #16: Loss = 0.7299147995728298
Iteration #17: Loss = 0.7251581698886054
Iteration #18: Loss = 0.7214934413833773
Iteration #19: Loss = 0.7187146789030123
Iteration #20: Loss = 0.7166497228927127
Iteration #21: Loss = 0.7151584029476908
Iteration #22: Loss = 0.7141278262377467
Iteration #23: Loss = 0.7134670904831522
Iteration #24: Loss = 0.7131026001391906
Iteration #25: Loss = 0.7129740353558048
Iteration #26: Loss = 0.7130307877642803
Iteration #27: Loss = 0.7132291625431383
Iteration #28: Loss = 0.7135306252190945
Iteration #29: Loss = 0.7139008479793884
Iteration #30: Loss = 0.714309227504411
Iteration #31: Loss = 0.714728804218876
Iteration #32: Loss = 0.715136513342701
Iteration #33: Loss = 0.7155135124667155
Iteration #34: Loss = 0.7158453369296702
Iteration #35: Loss = 0.7161218503952342
Iteration #36: Loss = 0.7163370586444316
Iteration #37: Loss = 0.7164887841660481
Iteration #38: Loss = 0.7165781718551991
Iteration #39: Loss = 0.7166090755703904
Iteration #40: Loss = 0.716587414782993
Iteration #41: Loss = 0.7165205380906725
Iteration #42: Loss = 0.71641659740609
Iteration #43: Loss = 0.7162839737206957
Iteration #44: Loss = 0.7161308115806307
Iteration #45: Loss = 0.7159646730003498
Iteration #46: Loss = 0.7157922901990212
Iteration #47: Loss = 0.7156194117598945
Iteration #48: Loss = 0.7154507399038388
Iteration #49: Loss = 0.7152899351699595
Iteration #50: Loss = 0.7151396635403856
Iteration #51: Loss = 0.7150016784398069
Iteration #52: Loss = 0.7148769304976087
Iteration #53: Loss = 0.7147656884540912
Iteration #54: Loss = 0.7146676604905268
Iteration #55: Loss = 0.7145821147373048
Iteration #56: Loss = 0.71450799463603
Iteration #57: Loss = 0.7144440229903014
Iteration #58: Loss = 0.7143887945088073
Iteration #59: Loss = 0.7143408576283448
Iteration #60: Loss = 0.7142987830696507
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.3968609865470852
Top 20 Accuracy: 0.4663677130044843
Top N+5 Accuracy: 0.43946188340807174
Testing model with K = 4 and lambda = 0.01
Beginning to train
Iteration #1: Loss = 0.9607808263822225
Iteration #2: Loss = 0.9479566728619565
Iteration #3: Loss = 0.9332756742877796
Iteration #4: Loss = 0.916059603477338
Iteration #5: Loss = 0.8962477740608993
Iteration #6: Loss = 0.8740969137369556
Iteration #7: Loss = 0.8501989726765944
Iteration #8: Loss = 0.8254768090961692
Iteration #9: Loss = 0.8010753123003861
Iteration #10: Loss = 0.7781639397518414
Iteration #11: Loss = 0.7577216386626855
Iteration #12: Loss = 0.7403831527868291
Iteration #13: Loss = 0.7263833549710975
Iteration #14: Loss = 0.7155953150608916
Iteration #15: Loss = 0.7076265758978678
Iteration #16: Loss = 0.7019455895436122
Iteration #17: Loss = 0.6980086733713377
Iteration #18: Loss = 0.6953428531176461
Iteration #19: Loss = 0.69357250538439
Iteration #20: Loss = 0.6924107698723283
Iteration #21: Loss = 0.6916432771867667
Iteration #22: Loss = 0.6911199780527517
Iteration #23: Loss = 0.6907463284121165
Iteration #24: Loss = 0.6904647838714582
Iteration #25: Loss = 0.6902404595932581
Iteration #26: Loss = 0.6900503500680026
Iteration #27: Loss = 0.6898753398664289
Iteration #28: Loss = 0.6897060669695553
Iteration #29: Loss = 0.6895563939974185
Iteration #30: Loss = 0.6894614340223724
Iteration #31: Loss = 0.6894374898386039
Iteration #32: Loss = 0.6894272371262534
Iteration #33: Loss = 0.6893713607918436
Iteration #34: Loss = 0.689276336870791
Iteration #35: Loss = 0.6891739009883673
Iteration #36: Loss = 0.6890881071320936
Iteration #37: Loss = 0.6890244423455993
Iteration #38: Loss = 0.6889736893589726
Iteration #39: Loss = 0.6889223510932719
Iteration #40: Loss = 0.6888610818053399
Iteration #41: Loss = 0.6887862633429988
Iteration #42: Loss = 0.688699354506881
Iteration #43: Loss = 0.6886069455810616
Iteration #44: Loss = 0.6885196144077141
Iteration #45: Loss = 0.6884469089012079
Iteration #46: Loss = 0.688388546248646
Iteration #47: Loss = 0.6883327785384538
Iteration #48: Loss = 0.6882715695862907
Iteration #49: Loss = 0.6882077334067526
Iteration #50: Loss = 0.6881466300618397
Iteration #51: Loss = 0.6880882481118826
Iteration #52: Loss = 0.6880294665417163
Iteration #53: Loss = 0.6879701320114334
Iteration #54: Loss = 0.6879129657479208
Iteration #55: Loss = 0.6878607098113003
Iteration #56: Loss = 0.6878138464248934
Iteration #57: Loss = 0.6877693408963065
Iteration #58: Loss = 0.6877226017064144
Iteration #59: Loss = 0.6876712805592348
Iteration #60: Loss = 0.6876161784333378
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.43609865470852016
Top 20 Accuracy: 0.4876681614349776
Top N+5 Accuracy: 0.45403587443946186
Testing model with K = 4 and lambda = 0.05
Beginning to train
Iteration #1: Loss = 0.9602880910708925
Iteration #2: Loss = 0.9478642465818252
Iteration #3: Loss = 0.9339741241508993
Iteration #4: Loss = 0.9178115458592353
Iteration #5: Loss = 0.8991160755985116
Iteration #6: Loss = 0.8778772889996034
Iteration #7: Loss = 0.854506137435433
Iteration #8: Loss = 0.8298557564647647
Iteration #9: Loss = 0.8051153090329389
Iteration #10: Loss = 0.7815869595587129
Iteration #11: Loss = 0.7604178641186169
Iteration #12: Loss = 0.7423793364146138
Iteration #13: Loss = 0.7277722715927195
Iteration #14: Loss = 0.7164726884031533
Iteration #15: Loss = 0.708072437938809
Iteration #16: Loss = 0.7020438073862263
Iteration #17: Loss = 0.6978584604116056
Iteration #18: Loss = 0.6950442857016812
Iteration #19: Loss = 0.6932059350451539
Iteration #20: Loss = 0.6920314887487418
Iteration #21: Loss = 0.6912902506276452
Iteration #22: Loss = 0.6908201887226234
Iteration #23: Loss = 0.6905120085196037
Iteration #24: Loss = 0.6902955504290773
Iteration #25: Loss = 0.6901266844229197
Iteration #26: Loss = 0.6899766641779154
Iteration #27: Loss = 0.6898288171758592
Iteration #28: Loss = 0.6896794372744379
Iteration #29: Loss = 0.6895395610527953
Iteration #30: Loss = 0.6894315865411302
Iteration #31: Loss = 0.6893700332125303
Iteration #32: Loss = 0.6893227106156277
Iteration #33: Loss = 0.6892516365172883
Iteration #34: Loss = 0.6891503334952782
Iteration #35: Loss = 0.6890299496751323
Iteration #36: Loss = 0.6889195895343594
Iteration #37: Loss = 0.6888357139623645
Iteration #38: Loss = 0.6887652011175056
Iteration #39: Loss = 0.6887004508281411
Iteration #40: Loss = 0.6886475372095772
Iteration #41: Loss = 0.6885943947915955
Iteration #42: Loss = 0.6885232477130295
Iteration #43: Loss = 0.6884387796926783
Iteration #44: Loss = 0.6883520216361023
Iteration #45: Loss = 0.6882698164330256
Iteration #46: Loss = 0.688195699402317
Iteration #47: Loss = 0.688131031986609
Iteration #48: Loss = 0.6880735638197515
Iteration #49: Loss = 0.6880168221259922
Iteration #50: Loss = 0.6879539746025368
Iteration #51: Loss = 0.6878838738836979
Iteration #52: Loss = 0.6878110868665257
Iteration #53: Loss = 0.6877395464215154
Iteration #54: Loss = 0.6876711059365822
Iteration #55: Loss = 0.6876089285760362
Iteration #56: Loss = 0.6875541173283772
Iteration #57: Loss = 0.6875049484690123
Iteration #58: Loss = 0.6874577610023407
Iteration #59: Loss = 0.6874086703763185
Iteration #60: Loss = 0.6873551904164816
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4405829596412556
Top 20 Accuracy: 0.4910313901345291
Top N+5 Accuracy: 0.4663677130044843
Testing model with K = 4 and lambda = 0.1
Beginning to train
Iteration #1: Loss = 0.9611766532111639
Iteration #2: Loss = 0.9487385730315029
Iteration #3: Loss = 0.9348156337383609
Iteration #4: Loss = 0.9186092685111711
Iteration #5: Loss = 0.8997487793151779
Iteration #6: Loss = 0.8782706344420641
Iteration #7: Loss = 0.8546414541928411
Iteration #8: Loss = 0.8297446792287824
Iteration #9: Loss = 0.8047728363676514
Iteration #10: Loss = 0.7810155671781382
Iteration #11: Loss = 0.7596159501164113
Iteration #12: Loss = 0.7413666706099952
Iteration #13: Loss = 0.7266100216036132
Iteration #14: Loss = 0.715259938196646
Iteration #15: Loss = 0.706921973629627
Iteration #16: Loss = 0.7010476854260301
Iteration #17: Loss = 0.6970624492434171
Iteration #18: Loss = 0.6944512691114902
Iteration #19: Loss = 0.6927953307549094
Iteration #20: Loss = 0.6917612877102289
Iteration #21: Loss = 0.6911015755171303
Iteration #22: Loss = 0.6906669451792593
Iteration #23: Loss = 0.6903749367248317
Iteration #24: Loss = 0.6901742783772795
Iteration #25: Loss = 0.6900281884658135
Iteration #26: Loss = 0.689911716117364
Iteration #27: Loss = 0.6898112366696859
Iteration #28: Loss = 0.6897197513815543
Iteration #29: Loss = 0.6896330444803594
Iteration #30: Loss = 0.6895468095493543
Iteration #31: Loss = 0.6894558706803848
Iteration #32: Loss = 0.6893555974623247
Iteration #33: Loss = 0.689243486030417
Iteration #34: Loss = 0.6891204702412186
Iteration #35: Loss = 0.6889923142593873
Iteration #36: Loss = 0.688869747703488
Iteration #37: Loss = 0.6887639569791357
Iteration #38: Loss = 0.6886790142243184
Iteration #39: Loss = 0.6886090964934697
Iteration #40: Loss = 0.6885478102051593
Iteration #41: Loss = 0.6884938076142514
Iteration #42: Loss = 0.6884446737920681
Iteration #43: Loss = 0.6883954925773628
Iteration #44: Loss = 0.6883422558637273
Iteration #45: Loss = 0.6882806661102795
Iteration #46: Loss = 0.6882115696790356
Iteration #47: Loss = 0.6881390530911213
Iteration #48: Loss = 0.6880686421794041
Iteration #49: Loss = 0.6880059493075371
Iteration #50: Loss = 0.687952537986307
Iteration #51: Loss = 0.6879080023651486
Iteration #52: Loss = 0.6878709910936006
Iteration #53: Loss = 0.6878393856378772
Iteration #54: Loss = 0.6878107485683345
Iteration #55: Loss = 0.6877828895156591
Iteration #56: Loss = 0.6877545688096107
Iteration #57: Loss = 0.6877259956519415
Iteration #58: Loss = 0.6876983794755204
Iteration #59: Loss = 0.687673009543434
Iteration #60: Loss = 0.6876505576995253
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4428251121076233
Top 20 Accuracy: 0.5033632286995515
Top N+5 Accuracy: 0.47197309417040356
Testing model with K = 4 and lambda = 0.5
Beginning to train
Iteration #1: Loss = 0.9607708677284229
Iteration #2: Loss = 0.9478354809577713
Iteration #3: Loss = 0.9344343899885186
Iteration #4: Loss = 0.9196574494596534
Iteration #5: Loss = 0.9028439243045956
Iteration #6: Loss = 0.8833291649615194
Iteration #7: Loss = 0.8610625487013835
Iteration #8: Loss = 0.8367424905056046
Iteration #9: Loss = 0.8115940518617991
Iteration #10: Loss = 0.7870817950913737
Iteration #11: Loss = 0.7646186487059109
Iteration #12: Loss = 0.7452911928328928
Iteration #13: Loss = 0.7296698204092278
Iteration #14: Loss = 0.7177718927026534
Iteration #15: Loss = 0.7091806112849758
Iteration #16: Loss = 0.7032463176465135
Iteration #17: Loss = 0.6992787242139875
Iteration #18: Loss = 0.6966751966264217
Iteration #19: Loss = 0.6949764555111191
Iteration #20: Loss = 0.6938671552826964
Iteration #21: Loss = 0.6931464785684531
Iteration #22: Loss = 0.6926863114216363
Iteration #23: Loss = 0.6923954958298326
Iteration #24: Loss = 0.6922150406678115
Iteration #25: Loss = 0.6921162268345038
Iteration #26: Loss = 0.692090696891366
Iteration #27: Loss = 0.6921379018371427
Iteration #28: Loss = 0.6922552275827708
Iteration #29: Loss = 0.692436538810588
Iteration #30: Loss = 0.6926778923554986
Iteration #31: Loss = 0.6929765523433756
Iteration #32: Loss = 0.6933281549881164
Iteration #33: Loss = 0.6937256151470055
Iteration #34: Loss = 0.6941580121191683
Iteration #35: Loss = 0.6946102018482382
Iteration #36: Loss = 0.6950633308005015
Iteration #37: Loss = 0.6954963235495193
Iteration #38: Loss = 0.6958885196468132
Iteration #39: Loss = 0.6962219461329359
Iteration #40: Loss = 0.6964830326012849
Iteration #41: Loss = 0.6966637165370535
Iteration #42: Loss = 0.6967617278099043
Iteration #43: Loss = 0.6967801584446411
Iteration #44: Loss = 0.6967265347193026
Iteration #45: Loss = 0.6966115773627214
Iteration #46: Loss = 0.6964478421373038
Iteration #47: Loss = 0.6962484549408332
Iteration #48: Loss = 0.6960260875225707
Iteration #49: Loss = 0.6957921975712095
Iteration #50: Loss = 0.6955565096517484
Iteration #51: Loss = 0.6953267503376339
Iteration #52: Loss = 0.6951086510454251
Iteration #53: Loss = 0.694906157048668
Iteration #54: Loss = 0.6947217285118696
Iteration #55: Loss = 0.6945566446472005
Iteration #56: Loss = 0.6944112697920102
Iteration #57: Loss = 0.6942852637782024
Iteration #58: Loss = 0.6941777391831538
Iteration #59: Loss = 0.6940873918325752
Iteration #60: Loss = 0.6940126245220275
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4439461883408072
Top 20 Accuracy: 0.49887892376681614
Top N+5 Accuracy: 0.460762331838565
Testing model with K = 4 and lambda = 1
Beginning to train
Iteration #1: Loss = 0.9599160077877077
Iteration #2: Loss = 0.9440201407961445
Iteration #3: Loss = 0.9258731214400113
Iteration #4: Loss = 0.905396433625854
Iteration #5: Loss = 0.8830389015355915
Iteration #6: Loss = 0.8594760184323565
Iteration #7: Loss = 0.8356341070443918
Iteration #8: Loss = 0.812592202531226
Iteration #9: Loss = 0.7913327661587978
Iteration #10: Loss = 0.7725660700322678
Iteration #11: Loss = 0.756666682309589
Iteration #12: Loss = 0.743688860648445
Iteration #13: Loss = 0.7334353437703218
Iteration #14: Loss = 0.725552663407466
Iteration #15: Loss = 0.7196253957900259
Iteration #16: Loss = 0.7152488798756458
Iteration #17: Loss = 0.7120714807766155
Iteration #18: Loss = 0.7098096883953653
Iteration #19: Loss = 0.7082457800122132
Iteration #20: Loss = 0.7072169849222998
Iteration #21: Loss = 0.7066022934551391
Iteration #22: Loss = 0.706310466711535
Iteration #23: Loss = 0.7062709503487725
Iteration #24: Loss = 0.7064274477745158
Iteration #25: Loss = 0.7067329662514439
Iteration #26: Loss = 0.7071460593666777
Iteration #27: Loss = 0.7076285915867019
Iteration #28: Loss = 0.7081450632784178
Iteration #29: Loss = 0.7086630878127922
Iteration #30: Loss = 0.7091543980234826
Iteration #31: Loss = 0.7095958718089076
Iteration #32: Loss = 0.7099702762669339
Iteration #33: Loss = 0.710266557077656
Iteration #34: Loss = 0.7104796258907133
Iteration #35: Loss = 0.7106097450521761
Iteration #36: Loss = 0.7106616605633652
Iteration #37: Loss = 0.7106435840190013
Iteration #38: Loss = 0.7105660912088098
Iteration #39: Loss = 0.7104410335653267
Iteration #40: Loss = 0.7102805700259246
Iteration #41: Loss = 0.7100963846146537
Iteration #42: Loss = 0.7098991111943284
Iteration #43: Loss = 0.7096979629877196
Iteration #44: Loss = 0.7095005401398413
Iteration #45: Loss = 0.7093127732110742
Iteration #46: Loss = 0.7091389698448768
Iteration #47: Loss = 0.7089819427215074
Iteration #48: Loss = 0.7088431921265879
Iteration #49: Loss = 0.7087231146579945
Iteration #50: Loss = 0.7086212180949056
Iteration #51: Loss = 0.7085363281412898
Iteration #52: Loss = 0.7084667770537176
Iteration #53: Loss = 0.7084105725397244
Iteration #54: Loss = 0.7083655484851257
Iteration #55: Loss = 0.7083294953388865
Iteration #56: Loss = 0.7083002677354661
Iteration #57: Loss = 0.7082758697249046
Iteration #58: Loss = 0.7082545182418747
Iteration #59: Loss = 0.7082346858285826
Iteration #60: Loss = 0.7082151246923823
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.3867713004484305
Top 20 Accuracy: 0.46300448430493274
Top N+5 Accuracy: 0.4260089686098655
Testing model with K = 5 and lambda = 0.01
Beginning to train
Iteration #1: Loss = 0.9620970773490668
Iteration #2: Loss = 0.9504213137208539
Iteration #3: Loss = 0.9376113450669921
Iteration #4: Loss = 0.9227255485714505
Iteration #5: Loss = 0.905291838754631
Iteration #6: Loss = 0.8849337579121591
Iteration #7: Loss = 0.8617316486743261
Iteration #8: Loss = 0.8364202483686222
Iteration #9: Loss = 0.8103436222659567
Iteration #10: Loss = 0.7851878476333394
Iteration #11: Loss = 0.762563966593673
Iteration #12: Loss = 0.7435828821313213
Iteration #13: Loss = 0.7286235137481561
Iteration #14: Loss = 0.7174054669594423
Iteration #15: Loss = 0.709283228128653
Iteration #16: Loss = 0.7035364900649503
Iteration #17: Loss = 0.6995268038627229
Iteration #18: Loss = 0.6967454004006308
Iteration #19: Loss = 0.6948125170457049
Iteration #20: Loss = 0.6934585115526597
Iteration #21: Loss = 0.6924976825422052
Iteration #22: Loss = 0.6917968472321797
Iteration #23: Loss = 0.6912674869122065
Iteration #24: Loss = 0.6908686694877788
Iteration #25: Loss = 0.6905824664347024
Iteration #26: Loss = 0.6903826658730575
Iteration #27: Loss = 0.6902285735941479
Iteration #28: Loss = 0.6900974047289348
Iteration #29: Loss = 0.6899849137131159
Iteration #30: Loss = 0.6898890444961491
Iteration #31: Loss = 0.6898018908447595
Iteration #32: Loss = 0.6897145507622863
Iteration #33: Loss = 0.6896184052230087
Iteration #34: Loss = 0.6895102219867523
Iteration #35: Loss = 0.6894036462398018
Iteration #36: Loss = 0.6893273207444458
Iteration #37: Loss = 0.6892755464888659
Iteration #38: Loss = 0.6891926428389173
Iteration #39: Loss = 0.6890874899488088
Iteration #40: Loss = 0.6890078690939856
Iteration #41: Loss = 0.6889679443553277
Iteration #42: Loss = 0.6889200210682007
Iteration #43: Loss = 0.6888417597459152
Iteration #44: Loss = 0.6887528984037345
Iteration #45: Loss = 0.6886778841368415
Iteration #46: Loss = 0.6886143547539505
Iteration #47: Loss = 0.6885389008863024
Iteration #48: Loss = 0.6884468843663178
Iteration #49: Loss = 0.6883546742327914
Iteration #50: Loss = 0.6882787414150171
Iteration #51: Loss = 0.6882208891521675
Iteration #52: Loss = 0.6881639248068209
Iteration #53: Loss = 0.6880917297405112
Iteration #54: Loss = 0.6880072694689519
Iteration #55: Loss = 0.6879304481241092
Iteration #56: Loss = 0.6878804718100785
Iteration #57: Loss = 0.687848885859682
Iteration #58: Loss = 0.6878059876634375
Iteration #59: Loss = 0.6877425091876156
Iteration #60: Loss = 0.6876702784012415
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4461883408071749
Top 20 Accuracy: 0.5067264573991032
Top N+5 Accuracy: 0.476457399103139
Testing model with K = 5 and lambda = 0.05
Beginning to train
Iteration #1: Loss = 0.961883647613248
Iteration #2: Loss = 0.9500236509433253
Iteration #3: Loss = 0.9365903971653692
Iteration #4: Loss = 0.9204907708281131
Iteration #5: Loss = 0.9014787482307143
Iteration #6: Loss = 0.8794784659790745
Iteration #7: Loss = 0.8549035933300905
Iteration #8: Loss = 0.8287649723478475
Iteration #9: Loss = 0.8025166894498628
Iteration #10: Loss = 0.7777484709305167
Iteration #11: Loss = 0.7558250794153053
Iteration #12: Loss = 0.7376006829357387
Iteration #13: Loss = 0.7233111132057697
Iteration #14: Loss = 0.7126688112384262
Iteration #15: Loss = 0.7050776620637229
Iteration #16: Loss = 0.6998447505354772
Iteration #17: Loss = 0.6963319968293726
Iteration #18: Loss = 0.6940263582461806
Iteration #19: Loss = 0.6925460079791782
Iteration #20: Loss = 0.6916139985747832
Iteration #21: Loss = 0.6910232726514701
Iteration #22: Loss = 0.6906346428612409
Iteration #23: Loss = 0.690367525999698
Iteration #24: Loss = 0.6901758522980451
Iteration #25: Loss = 0.6900289891936091
Iteration #26: Loss = 0.689902256783654
Iteration #27: Loss = 0.6897776473428071
Iteration #28: Loss = 0.6896511620552084
Iteration #29: Loss = 0.6895362302324634
Iteration #30: Loss = 0.6894539093073766
Iteration #31: Loss = 0.6894007860348901
Iteration #32: Loss = 0.689322422207957
Iteration #33: Loss = 0.689212854016974
Iteration #34: Loss = 0.6891176403705361
Iteration #35: Loss = 0.6890355662660957
Iteration #36: Loss = 0.6889428710648289
Iteration #37: Loss = 0.6888405172441024
Iteration #38: Loss = 0.6887448132320644
Iteration #39: Loss = 0.6886763229230471
Iteration #40: Loss = 0.6886263581138158
Iteration #41: Loss = 0.6885547676007042
Iteration #42: Loss = 0.6884622330726893
Iteration #43: Loss = 0.6883644068000547
Iteration #44: Loss = 0.6882700809021993
Iteration #45: Loss = 0.6881788430554773
Iteration #46: Loss = 0.688086711331909
Iteration #47: Loss = 0.6879927481015726
Iteration #48: Loss = 0.6879036252333383
Iteration #49: Loss = 0.6878283751561658
Iteration #50: Loss = 0.6877620605609666
Iteration #51: Loss = 0.6876880171230494
Iteration #52: Loss = 0.6876029006965257
Iteration #53: Loss = 0.6875140303433162
Iteration #54: Loss = 0.6874257763044574
Iteration #55: Loss = 0.687338527600594
Iteration #56: Loss = 0.6872524811593905
Iteration #57: Loss = 0.6871681702141537
Iteration #58: Loss = 0.6870865949798368
Iteration #59: Loss = 0.6870099715871996
Iteration #60: Loss = 0.6869407031167797
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4495515695067265
Top 20 Accuracy: 0.49887892376681614
Top N+5 Accuracy: 0.47197309417040356
Testing model with K = 5 and lambda = 0.1
Beginning to train
Iteration #1: Loss = 0.96079552511098
Iteration #2: Loss = 0.9477673424068559
Iteration #3: Loss = 0.9325104235641727
Iteration #4: Loss = 0.914227935991589
Iteration #5: Loss = 0.8927856838083323
Iteration #6: Loss = 0.8685612814571508
Iteration #7: Loss = 0.8424305109452777
Iteration #8: Loss = 0.8156596592617292
Iteration #9: Loss = 0.7897495456601265
Iteration #10: Loss = 0.7661734704289284
Iteration #11: Loss = 0.7460499965847869
Iteration #12: Loss = 0.7299034327146261
Iteration #13: Loss = 0.71764090364724
Iteration #14: Loss = 0.7087327864217432
Iteration #15: Loss = 0.702470323759557
Iteration #16: Loss = 0.6981697080958322
Iteration #17: Loss = 0.6952723917085373
Iteration #18: Loss = 0.6933588989007774
Iteration #19: Loss = 0.6921164820860072
Iteration #20: Loss = 0.6913068536034848
Iteration #21: Loss = 0.6907712536505133
Iteration #22: Loss = 0.6904131143767027
Iteration #23: Loss = 0.690172438529455
Iteration #24: Loss = 0.6900116689845227
Iteration #25: Loss = 0.6898975873277046
Iteration #26: Loss = 0.689792962132179
Iteration #27: Loss = 0.689678415156093
Iteration #28: Loss = 0.689554076784279
Iteration #29: Loss = 0.6894238745399827
Iteration #30: Loss = 0.6892899013504401
Iteration #31: Loss = 0.689152499152561
Iteration #32: Loss = 0.6890166107539002
Iteration #33: Loss = 0.6888986013612346
Iteration #34: Loss = 0.6888083854284047
Iteration #35: Loss = 0.6887230782825339
Iteration #36: Loss = 0.6886171291666281
Iteration #37: Loss = 0.688500037970306
Iteration #38: Loss = 0.6883834492927189
Iteration #39: Loss = 0.6882609188338394
Iteration #40: Loss = 0.6881311119589573
Iteration #41: Loss = 0.6880035139240221
Iteration #42: Loss = 0.68788761415212
Iteration #43: Loss = 0.687786530144839
Iteration #44: Loss = 0.6876957329365219
Iteration #45: Loss = 0.6876067353190181
Iteration #46: Loss = 0.6875132327495068
Iteration #47: Loss = 0.6874157364911275
Iteration #48: Loss = 0.6873185362133191
Iteration #49: Loss = 0.6872249124240327
Iteration #50: Loss = 0.6871366995553951
Iteration #51: Loss = 0.687054489654411
Iteration #52: Loss = 0.6869780126743738
Iteration #53: Loss = 0.6869054385256372
Iteration #54: Loss = 0.6868335865123858
Iteration #55: Loss = 0.686759989310597
Iteration #56: Loss = 0.6866850413826626
Iteration #57: Loss = 0.6866109496008436
Iteration #58: Loss = 0.6865397643999389
Iteration #59: Loss = 0.686473983271437
Iteration #60: Loss = 0.6864144384318182
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4439461883408072
Top 20 Accuracy: 0.5168161434977578
Top N+5 Accuracy: 0.4730941704035874
Testing model with K = 5 and lambda = 0.5
Beginning to train
Iteration #1: Loss = 0.9629589787341405
Iteration #2: Loss = 0.9499358650184692
Iteration #3: Loss = 0.9351055810035962
Iteration #4: Loss = 0.9176278079229953
Iteration #5: Loss = 0.8971403821220101
Iteration #6: Loss = 0.8737555940172174
Iteration #7: Loss = 0.8480657568569163
Iteration #8: Loss = 0.8211351699851749
Iteration #9: Loss = 0.794430494506497
Iteration #10: Loss = 0.769576129743596
Iteration #11: Loss = 0.747987857911686
Iteration #12: Loss = 0.7305328098353876
Iteration #13: Loss = 0.7173756414261258
Iteration #14: Loss = 0.7080742793639593
Iteration #15: Loss = 0.7018452190498655
Iteration #16: Loss = 0.6978420483916629
Iteration #17: Loss = 0.6953370841992638
Iteration #18: Loss = 0.6937882903390885
Iteration #19: Loss = 0.6928307955225058
Iteration #20: Loss = 0.6922360135678048
Iteration #21: Loss = 0.6918631263836631
Iteration #22: Loss = 0.691621729231471
Iteration #23: Loss = 0.6914602410377718
Iteration #24: Loss = 0.6913574010406529
Iteration #25: Loss = 0.6913090778257807
Iteration #26: Loss = 0.6913189736677035
Iteration #27: Loss = 0.6913918136101297
Iteration #28: Loss = 0.6915277203762277
Iteration #29: Loss = 0.6917201374068459
Iteration #30: Loss = 0.6919597225345394
Iteration #31: Loss = 0.692240176584991
Iteration #32: Loss = 0.6925577304424265
Iteration #33: Loss = 0.6929057633805465
Iteration #34: Loss = 0.6932714087066804
Iteration #35: Loss = 0.6936371103864717
Iteration #36: Loss = 0.6939834357950986
Iteration #37: Loss = 0.6942910885108095
Iteration #38: Loss = 0.6945428307585815
Iteration #39: Loss = 0.6947254397855827
Iteration #40: Loss = 0.6948312307700882
Iteration #41: Loss = 0.6948587572004518
Iteration #42: Loss = 0.69481254287023
Iteration #43: Loss = 0.6947019535306881
Iteration #44: Loss = 0.6945395179264489
Iteration #45: Loss = 0.6943390948052848
Iteration #46: Loss = 0.6941142449032641
Iteration #47: Loss = 0.6938770491266605
Iteration #48: Loss = 0.6936374680925445
Iteration #49: Loss = 0.6934031955356812
Iteration #50: Loss = 0.6931798462811395
Iteration #51: Loss = 0.6929712806040613
Iteration #52: Loss = 0.69277992417829
Iteration #53: Loss = 0.6926070458238165
Iteration #54: Loss = 0.6924530084712838
Iteration #55: Loss = 0.6923174900326482
Iteration #56: Loss = 0.6921996522239277
Iteration #57: Loss = 0.6920982585221759
Iteration #58: Loss = 0.6920117686323606
Iteration #59: Loss = 0.691938429579562
Iteration #60: Loss = 0.6918763594884143
used 59 its
Evaluated on file cv_recent.txt with 247 Cases and 892 solves
Top 10 Accuracy: 0.4495515695067265
Top 20 Accuracy: 0.5123318385650224
Top N+5 Accuracy: 0.4854260089686099
Testing model with K = 5 and lambda = 1
Beginning to train
Iteration #1: Loss = 0.9613974090694947
Iteration #2: Loss = 0.9462234264416323
Iteration #3: Loss = 0.9287673620070388
Iteration #4: Loss = 0.908292832370664
Iteration #5: Loss = 0.8850175301978053
Iteration #6: Loss = 0.8595092590913614
Iteration #7: Loss = 0.8330631126279587
Iteration #8: Loss = 0.8073023644369183
Iteration #9: Loss = 0.7836894600373793
Iteration #10: Loss = 0.7632540357232095
Iteration #11: Loss = 0.7464869134648684
Iteration #12: Loss = 0.733372646803648
Iteration #13: Loss = 0.7235260301435932
Iteration #14: Loss = 0.7163718982710673
Iteration #15: Loss = 0.7113041382201863
Iteration #16: Loss = 0.7077868283599501
Iteration #17: Loss = 0.7053955191299103
Iteration #18: Loss = 0.7038177069937216
Iteration #19: Loss = 0.7028336581116787
Iteration #20: Loss = 0.7022913680883681
Iteration #21: Loss = 0.7020846597598372
Iteration #22: Loss = 0.7021379398746734
Iteration #23: Loss = 0.7023943989690716
Iteration #24: Loss = 0.7028068374079639
Iteration #25: Loss = 0.7033324654295705
Iteration #26: Loss = 0.7039306566619439
Iteration #27: Loss = 0.7045621619553051
Iteration #28: Loss = 0.7051894841013983
Iteration #29: Loss = 0.705778302276452
Iteration #30: Loss = 0.7062993999419923
Iteration #31: Loss = 0.7067304606206999
Iteration #32: Loss = 0.707057249587747
Iteration #33: Loss = 0.7072739436275062
Iteration #34: Loss = 0.7073826153624363
Iteration #35: Loss = 0.7073919983891943
Iteration #36: Loss = 0.7073157335521019
Iteration #37: Loss = 0.7071703872650467
Iteration #38: Loss = 0.7069735689879331
Iteration #39: Loss = 0.7067424062327801
Iteration #40: Loss = 0.7064924860011708
Iteration #41: Loss = 0.7062372278341754
Iteration #42: Loss = 0.7059875842430486
Iteration #43: Loss = 0.7057519660255808
Iteration #44: Loss = 0.7055363272377969
Iteration #45: Loss = 0.7053443753189532
Iteration #46: Loss = 0.7051778727179747
Iteration #47: Loss = 0.7050369827015549
Iteration #48: Loss = 0.7049206113316749
Iteration #49: Loss = 0.7048267185893928
Iteration #50: Loss = 0.7047525972600605
Iteration #51: Loss = 0.704695127219688
Iteration #52: Loss = 0.7046510059928702
Iteration #53: Loss = 0.7046169493877898
Iteration #54: Loss = 0.7045898565645591
Iteration #55: Loss = 0.7045669382691246
Iteration #56: Loss = 0.7045458089760096
Iteration #57: Loss = 0.7045245425026663
Iteration #58: Loss = 0.7045016904687097
Iteration #59: Loss = 0.7044762665767864
Iteration #60: Loss = 0.7044477047068147
used 59 its